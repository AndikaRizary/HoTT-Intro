\section{More inductive types}

Analogous to the type of natural numbers, many types can be specified as inductive types. In this lecture we introduce some further examples of inductive types: the unit type, the empty type, the booleans, coproducts, dependent pair types, and cartesian products. We also introduce the type of integers.

\subsection{The idea of general inductive types}

Just like the type of natural numbers, other inductive types are also specified by their \emph{constructors}, an \emph{induction principle}, and their \emph{computation rules}: 
\begin{enumerate}
\item The constructors tell what structure the inductive type comes equipped with. There may any finite number of constructors, even no constructors at all, in the specification of an inductive type. 
\item The induction principle specifies the data that should be provided in order to construct a section of an arbitrary type family over the inductive type. 
\item The computation rules assert that the inductively defined section agrees on the constructors with the data that was used to define the section. Thus, there is a computation rule for every constructor.
\end{enumerate}
The induction principle and computation rules can be generated automatically once the constructors are specified, but it goes beyond the scope of our course to describe general inductive types.
%For a more general treatment of inductive types, we refer to Chapter 5 of \cite{hottbook}.


\subsection{The unit type}
\index{unit type|(}
\index{inductive type!unit type|(}
A straightforward example of an inductive type is the \emph{unit type}, which has just one constructor. 
Its induction principle is analogous to just the base case of induction on the natural numbers.

\begin{defn}
We define the \define{unit type}\index{1 @{$\unit$}|see {unit type}}\index{unit type} to be a closed type $\unit$\index{unit type!is a closed type} equipped with a closed term\index{unit type!star@{$\ttt$}}
\begin{equation*}
\ttt:\unit,
\end{equation*}
satisfying the induction principle\index{induction principle!of unit type}\index{unit type!induction principle} that for any type family of types $P(x)$ indexed by $x:\unit$, there is a term\index{indunit@{$\indunit$}}\index{unit type!indunit@{$\indunit$}}
\begin{equation*}
\indunit : P(\ttt)\to\prd{x:\unit}P(x)
\end{equation*}
for which the computation rule\index{computation rules!of unit type}\index{unit type!computation rules}
\begin{equation*}
\indunit(p,\ttt) \jdeq p
\end{equation*}
holds. Sometimes we write $\lam{\ttt}p$ for $\indunit(p)$.
\end{defn}

The induction principle can also be used to define ordinary functions out of the unit type. Indeed, given a type $A$ we can first weaken it to obtain the constant family over $\unit$, with value $A$. Then the induction principle of the unit type provides a function
\begin{equation*}
  \indunit : A \to (\unit\to A).
\end{equation*}
In other words, by the induction principle for the unit type we obtain for every $x:A$ a function $\mathsf{pt}_x\defeq\indunit(x):\unit\to A$.\index{ptx@{$\mathsf{pt}_x$}}
\index{unit type|)}
\index{inductive type!unit type|)}

\subsection{The empty type}
\index{empty type|(}
\index{inductive type!empty type|(}
The empty type is a degenerate example of an inductive type. It does \emph{not} come equipped with any constructors, and therefore there are also no computation rules. The induction principle merely asserts that any type family has a section. In other words: if we assume the empty type has a term, then we can prove anything.

\begin{defn}
We define the \define{empty type}\index{0 @{$\emptyt$}|see {empty type}} to be a type $\emptyt$ satisfying the induction principle\index{induction principle!of empty type}\index{empty type!induction principle} that for any family of types $P(x)$ indexed by $x:\empty$, there is a term\index{indempty@{$\indempty$}}\index{empty type!indempty@{$\indempty$}}
\begin{equation*}
\indempty : \prd{x:\emptyt}P(x).
\end{equation*}
\end{defn}

The induction principle for the empty type can also be used to construct a function
\begin{equation*}
  \emptyt\to A
\end{equation*}
for any type $A$. Indeed, to obtain this function one first weakens $A$ to obtain the constant family over $\emptyt$ with value $A$, and then the induction principle gives the desired function.

Thus we see that from the empty type anything follows. Therefore, we we see that anything follows from $A$, if we have a function from $A$ to the empty type. This motivates the following definition.

\begin{defn}
  For any type $A$ we define \define{negation}\index{negation!of types}\index{neg A@{$\neg A$}|see {negation}} of $A$ by
  \begin{equation*}
    \neg A\defeq A\to\emptyt.
  \end{equation*}
\end{defn}

Since $\neg A$ is the type of functions from $A$ to $\emptyt$, a proof of $\neg A$ is given by assuming that $A$ holds, and then deriving a contradiction. This proof technique is called \define{proof of negation}\index{proof of negation}. Proofs of negation are not to be confused with \emph{proofs by contradiction}\index{proof by contradiction}. In type theory there is no way of obtaining a term of type $A$ from a term of type $(A\to \emptyt)\to\emptyt$.
\index{empty type|)}
\index{inductive type!empty type|)}

\subsection{The booleans}
\index{booleans}
\index{inductive type!booleans}

\begin{defn}
We define the \define{booleans}\index{2 @{$\bool$}|see {booleans}} to be a type $\bool$ that comes equipped with\index{booleans!btrue@{$\btrue$}}\index{booleans!bfalse@{$\bfalse$}}\index{0 2@{$\bfalse$}}\index{1 2@{$\btrue$}}
\begin{align*}
\bfalse & : \bool \\
\btrue & : \bool
\end{align*}
satisfying the induction principle\index{induction principle!of booleans}\index{booleans!induction principle} that for any family of types $P(x)$ indexed by $x:\bool$, there is a term\index{indbool@{$\indbool$}}
\begin{equation*}
\indbool : P(\bfalse)\to \Big(P(\btrue)\to \prd{x:\bool}P(x)\Big)
\end{equation*}
for which the computation rules\index{computation rules!of booleans}\index{booleans!computation rules}
\begin{align*}
\indbool(p_0,p_1,\bfalse) & \jdeq p_0 \\
\indbool(p_0,p_1,\btrue) & \jdeq p_1
\end{align*}
hold.
\end{defn}

Just as in the cases for the unit type and the empty type, the induction principle for the booleans can also be used to construct an ordinary function $\bool\to A$, provided that we can construct two terms of type $A$. Indeed, by the induction principle for the booleans there is a function
\begin{equation*}
  \indbool : A \to (A\to A^\bool)
\end{equation*}
for any type $A$.

\begin{eg}
  \index{boolean operations|(}\index{boolean logic|(}
  Using the induction principle of $\bool$ we can define all the operations of Boolean algebra\index{boolean algebra}. For example, the \define{boolean negation}\index{booleans!negation} operation $\neg : \bool \to \bool$\index{negation!of booleans} is defined by
  \begin{align*}
    \neg\btrue & \defeq \bfalse & \neg\bfalse & \defeq \btrue.
  \end{align*}
  The \define{boolean conjunction}\index{booleans!conjunction} operation $\blank\land\blank : \bool \to (\bool\to \bool)$ is defined by
  \begin{align*}
    \btrue\land\btrue & \defeq \btrue & \bfalse\land\btrue & \defeq \bfalse \\
    \btrue\land\bfalse & \defeq \bfalse & \bfalse\land\bfalse & \defeq \bfalse.
  \end{align*}
  The \define{boolean disjunction}\index{booleans!disjunction} operation $\blank\lor\blank : \bool \to (\bool\to \bool)$ is defined by
  \begin{align*}
    \btrue\lor\btrue & \defeq \btrue & \bfalse\lor\btrue & \defeq \btrue \\
    \btrue\lor\bfalse & \defeq \btrue & \bfalse\lor\bfalse & \defeq \bfalse.
  \end{align*}  
  We leave the definitions of some of the other boolean operations as \cref{ex:boolean-operation}. Note that the method of defing the boolean operations by the induction principle of $\bool$ is not that different from defining them by truth tables\index{truth tables}.

  Boolean logic is important, but it won't be very prominent in this course. The reason is simple: in type theory it is more natural to use the `logic' of types that is provided by the inference rules.\index{boolean operations|)}\index{boolean logic|)}
\end{eg}
\index{booleans|)}
\index{inductive type!booleans|)}

\subsection{Coproducts and the type of integers}
\index{coproduct|(}
\index{inductive type!coproduct|(}
\begin{defn}
Let $A$ and $B$ be types. We define the \define{coproduct}\index{disjoint sum|see {coproduct}} $A+B$\index{plus ($+$)|see {coproduct}} to be a type that comes equipped with\index{inl@{$\inl$}}\index{coproduct!inl@{$\inl$}}\index{inr@{$\inr$}}\index{coproduct!inr@{$\inr$}}
\begin{align*}
\inl & : A \to A+B \\
\inr & : B \to A+B
\end{align*}
satisfying the induction principle\index{induction principle!of coproduct}\index{coproduct!induction principle} that for any family of types $P(x)$ indexed by $x:A+B$, there is a term\index{ind+@{$\ind{+}$}}\index{coproduct!ind+@{$\ind{+}$}}
\begin{equation*}
\ind{+} : \Big(\prd{x:A}P(\inl(x))\Big)\to\Big(\prd{y:B}P(\inr(y))\Big)\to\prd{z:A+B}P(z)
\end{equation*}
for which the computation rules\index{computation rules!of coproduct}\index{coproduct!computation rules}
\begin{align*}
\ind{+}(f,g,\inl(x)) & \jdeq f(x) \\
\inr{+}(f,g,\inr(y)) & \jdeq g(y)
\end{align*}
hold. Sometimes we write $[f,g]$ for $\ind{+}(f,g)$.
\end{defn}

The coproduct of two types is sometimes also called the \define{disjoint sum}. By the induction principle of coproducts it follows that we have a function
\begin{equation*}
  (A\to X) \to \big((B\to X) \to (A+B\to X)\big)
\end{equation*}
for any type $X$. Note that this special case of the induction principle of coproducts is very much like the elimination rule of disjunction in first order logic: if $P$, $P'$, and $Q$ are propositions, then we have
\begin{equation*}
  (P\to Q)\to \big((P'\to Q)\to (P\lor P'\to Q)\big).
\end{equation*}
Indeed, we can think of \emph{propositions as types} and of terms as their constructive proofs. Under this interpretation of type theory the coproduct is indeed the disjunction.

\index{integers|(}
An important example of a type that can be defined using coproducts is the type $\Z$ of integers.\index{coproduct!Z@{$\Z$}}

\begin{defn}
  We define the \define{integers}\index{Z@{$\Z$}|see {integers}} to be the type $\Z\defeq\nat+(\unit+\nat)$. The type of integers comes equipped with inclusion functions of the positive and negative integers\index{integers!in-pos@{$\mathsf{in\usc{}pos}$}}\index{integers!in-neg@{$\mathsf{in\usc{}neg}$}}
  \begin{align*}
    \mathsf{in\usc{}pos} & \defeq \inr\circ\inr \\
    \mathsf{in\usc{}neg} & \defeq \inl,
  \end{align*}
  which are both of type $\N\to\Z$, and the constants\index{integers!-1 Z@{$-1_\Z$}}\index{integers!0 Z@{$0_\Z$}}\index{integers!1 Z@{$1_\Z$}}\index{-1 Z@{$-1_\Z$}}\index{0 Z@{$0_\Z$}}\index{1 Z@{$1_{\Z}$}}
  \begin{align*}
    -1_\Z & \defeq \mathsf{in\usc{}neg}(0)\\
    0_\Z & \defeq \inr(\inl(\ttt))\\
    1_\Z & \defeq \mathsf{in\usc{}pos}(0).
  \end{align*}
\end{defn}

In the following lemma we derive an induction principle\index{induction principle!of Z@{of $\Z$}}\index{integers!induction principle} for $\Z$, which can be used in many familiar constructions on $\Z$, such as in the definitions of addition and multiplication.

\begin{lem}\label{lem:Z_ind}
  Consider a type family $P$ over $\Z$. If we are given
  \begin{align*}
    p_{-1} & :P(-1_\Z) \\
    p_{-S} & : \prd{n:\N}P(\mathsf{in\usc{}neg}(n))\to P(\mathsf{in\usc{}neg}(\succN(n)))\\
    p_{0} & : P(0_\Z) \\
    P_{1} & : P(1_\Z) \\
    P_{S} & : \prd{n:\N}P(\mathsf{in\usc{}pos}(n))\to P(\mathsf{in\usc{}pos}(\succN(n))),
  \end{align*}
  then we can construct a dependent function $f:\prd{k:\Z}P(k)$ for which the following judgmental equalities hold:\index{integers!computation rules}\index{computation rules!of Z@{of $\Z$}}
  \begin{align*}
    f(-1_\Z) & \jdeq p_{-1} \\
    f(\mathsf{in\usc{}neg}(\mathsf{succ}_\N(n))) & \jdeq p_{-S}(n,f(\mathsf{in\usc{}neg}(n))) \\
    f(0_\Z) & \jdeq p_{0} \\
    f(1_\Z) & \jdeq p_{1} \\
    f(\mathsf{in\usc{}pos}(\mathsf{succ}_\N(n))) & \jdeq p_S(n,f(\mathsf{in\usc{}pos}(n))).
  \end{align*}
\end{lem}

\begin{proof}
  Since $\Z$ is the coproduct of $\N$ and $\unit+\N$, it suffices to define
  \begin{align*}
    p_{inl} & : \prd{n:\N}P(\inl(n)) \\
    p_{inr} & : \prd{t:\unit+\N}P(\inr(t)).
  \end{align*}
  Note that $\mathsf{in\usc{}neg}\jdeq\inl$ and $-1_\Z\jdeq \mathsf{in\usc{}neg}(\zeroN)$. In order to define $p_{inl}$ we use induction on the natural numbers, so it suffices to define
  \begin{align*}
    p_{-1} & : P(-1) \\
    p_{-S} & : \prd{n:\N} P(\mathsf{in\usc{}neg}(n))\to P(\mathsf{in\usc{}neg}(\succN(n))).
  \end{align*}
  Similarly, we proceed by coproduct induction, followed by induction on $\unit$ in the left case and induction on $\N$ on the right case, in order to define $p_{inr}$. 
\end{proof}

As an application we define the successor function on the integers.

\begin{defn}
We define the \define{successor function}\index{successor function!on Z@{on $\Z$}}\index{function!succZ@{$\succZ$}} on the integers $\succZ:\Z\to\Z$\index{succZ@{$\succZ$}}\index{integers!succZ@{$\succZ$}} using the induction principle of \cref{lem:Z_ind}, taking
\begin{align*}
\succZ(-1_\Z) & \defeq 0_\N \\
\succZ(\mathsf{in\usc{}neg}(\succN(n))) & \defeq \mathsf{in\usc{}neg}(n) \\
\succZ(0_\Z) & \defeq 1_\N \\
\succZ(1_\Z) & \defeq \mathsf{in\usc{}pos}(1_\N) \\
\succZ(\mathsf{in\usc{}pos}(\succN(n))) & \defeq \mathsf{in\usc{}pos}(\succN(\succN(n))).
\end{align*}
\end{defn}
\index{integers|)}
\index{coproduct|)}
\index{inductive type!coproduct|)}

\subsection{Dependent pair types}

\index{dependent pair type|(}
\index{inductive type!dependent pair type|(}

Given a type family $B$ over $A$, we may consider pairs $(a,b)$ of terms, where $a:A$ and $b:B(a)$. Note that the type of $b$ depends on the first term in the pair, so we call such a pair a \define{dependent pair}\index{dependent pair}.

The \emph{dependent pair type} is an inductive type that is generated by the dependent pairs.


\begin{defn}
  Consider a type family $B$ over $A$.
  The \define{dependent pair type} (or $\Sigma$-type) \index{Sigma-type@{$\Sigma$-type}|see {dependent pair type}}is defined to be the inductive type $\sm{x:A}B(x)$ equipped with a \define{pairing function}\index{pairing function}\index{(-,-)@{$(\blank,\blank)$}}\index{dependent pair type!(-,-)@{$(\blank,\blank)$}}
\begin{equation*}
(\blank,\blank):\prd{x:A} \Big(B(x)\to \sm{y:A}B(y)\Big).
\end{equation*}
The induction principle\index{induction principle!of Sigma types@{of $\Sigma$-types}}\index{dependent pair type!induction principle} for $\sm{x:A}B(x)$ asserts that for any family of types $P(p)$ indexed by $p:\sm{x:A}B(x)$, there is a function\index{dependent pair type!indSigma@{$\ind{\Sigma}$}}\index{indSigma@{$\ind{\Sigma}$}}
\begin{equation*}
\ind{\Sigma}:\Big(\prd{x:A}{y:B(x)}P(x,y)\Big)\to\Big(\prd{p:\sm{x:A}B(x)}P(p)\Big).
\end{equation*}
satisfying the computation rule\index{computation rules!of Sigma types@{of $\Sigma$-types}}\index{dependent pair type!computation rule}
\begin{equation*}
\ind{\Sigma}(f,(x,y))\jdeq f(x,y).
\end{equation*}
Sometimes we write $\lam{(x,y)}f(x,y)$ for $\ind{\Sigma}(\lam{x}{y}f(x,y))$. 
\end{defn}

\begin{defn}
Given a type $A$ and a type family $B$ over $A$, the \define{first projection map}\index{first projection map}\index{projection maps!first projection}\index{dependent pair type!pr1@{$\proj 1$}}\index{pr1@{$\proj 1$}}\index{function!pr1@{$\proj 1$}}
\begin{equation*}
\proj 1:\Big(\sm{x:A}B(x)\Big)\to A
\end{equation*}
is defined by induction as
\begin{equation*}
\proj 1\defeq \lam{(x,y)}x.
\end{equation*}
The \define{second projection map}\index{second projection map}\index{projection map!second projection}\index{dependent pair type!pr2@{$\proj 2$}}\index{pr2@{$\proj 2$}}\index{function!pr2@{$\proj 2$}} is a dependent function
\begin{equation*}
\proj 2 : \prd{p:\sm{x:A}B(x)} B(\proj 1(p))
\end{equation*}
defined by induction as
\begin{equation*}
\proj 2\defeq \lam{(x,y)}y.
\end{equation*}
By the computation rule we have
\begin{align*}
\proj 1 (x,y) & \jdeq x \\
\proj 2 (x,y) & \jdeq y.
\end{align*}
\end{defn}
\index{dependent pair type|)}
\index{inductive type!dependent pair type|)}

\subsection{Cartesian products}

\index{cartesian product|(}
\index{inductive type!cartesian product|(}
A special case of the $\Sigma$-type occurs when the $B$ is a constant family over $A$, i.e., when $B$ is just a type.
In this case, the inductive type $\sm{x:A}B(x)$ is generated by \emph{ordinary} pairs $(x,y)$ where $x:A$ and $y:B$. In other words, if $B$ does not depend on $A$, then the type $\sm{x:A}B$ is the \emph{(cartesian) product} $A\times B$.
The cartesian product is a very common special case of the dependent pair type, just as the type $A\to B$ of ordinary functions from $A\to B$ is a common special case of the dependent product. Therefore we provide its specification along with the induction principle for cartesian products.

\begin{defn}
Consider two types $A$ and $B$. The \define{(cartesian) product}\index{product of types}\index{A x B@{$A\times B$}} of $A$ and $B$ is defined as the inductive type $A\times B$\index{times ($\times$)|see {cartesian product}} with constructor
\begin{equation*}
(\blank,\blank):A\to (B\to A\times B).
\end{equation*}
The induction principle\index{induction principle!of cartesian products}\index{cartesian product!induction principle} for $A\times B$ asserts that for any type family $P$ over $A\times B$, one has\index{indtimes@{$\ind{\times}$}}\index{cartesian product!indtimes@{$\ind{\times}$}}
\begin{equation*}
\ind{\times} : \Big(\prd{x:A}{y:B}P(a,b)\Big)\to\Big(\prd{p:A\times B} P(p)\Big)
\end{equation*}
satisfying the computation rule\index{computation rules!of cartesian product}\index{cartesian product!computation rule} that
\begin{align*}
\ind{\times}(f,(x,y)) & \jdeq f(x,y).
\end{align*}
\end{defn}

The projection maps are defined similarly to the projection maps of $\Sigma$-types. When one thinks of types as propositions\index{propositions as types!conjunction}, then $A\times B$ is interpreted as the conjunction of $A$ and $B$.
\index{cartesian product|)}
\index{inductive type!cartesian product|)}

\begin{exercises}
\item Write the rules for $\unit$, $\emptyt$, $\bool$, $A+B$, $\sm{x:A}B(x)$, and $A\times B$. As usual, present the rules in four sets:
  \begin{enumerate}
  \item A formation rule.
  \item Introduction rules.
  \item An elimination rule.
  \item Computation rules.
  \end{enumerate}
\item \label{ex:boolean-operation}Define the following operations of Boolean algebra:\index{boolean algebra}\index{booleans!exclusive disjunction}\index{booleans!implication}\index{booleans!if and only if}\index{booleans!Peirce's arrow}\index{booleans!Sheffer stroke}
  \begin{center}
    \begin{tabular}{ll}
      exclusive disjunction & $p \oplus q$ \\
      implication & $p \Rightarrow q$ \\
      if and only if & $p \Leftrightarrow q$ \\
      Peirce's arrow (neither \dots{} nor) & $p \downarrow q$ \\
      Sheffer stroke (not both) & $p\mid q$.
    \end{tabular}
  \end{center}
  Here $p$ and $q$ range over $\bool$. 
\item \label{ex:int_pred}\index{predecessor function}\index{function!predZ@{$\predZ$}}\index{integers!predZ@{$\predZ$}}\index{predZ@{$\predZ$}}Define the predecessor function $\mathsf{pred}_\Z:\Z\to \Z$.
\item \label{ex:int_group_ops}\index{group operations!on Z@{on $\Z$}}Define group operations
  \begin{align*}
    k,l & \mapsto k+l \\
    k & \mapsto -k
  \end{align*}
  on $\Z$.
\item Define multiplication on $\Z$.
\item Construct a function $F:\Z\to\Z$ that extends the Fibonacci sequence to the left
  \begin{equation*}
    \ldots,5,-3,2,-1,1,0,1,1,2,3,5,8,13,\ldots
  \end{equation*}
  in the expected way.
\item \label{ex:one_plus_one} Show that $\unit+\unit$ satisfies the same induction principle\index{induction principle!of booleans} as $\bool$, i.e., define
  \begin{align*}
    t_0 & : \unit + \unit \\
    t_1 & : \unit + \unit,
  \end{align*}
  and show that for any type family $P$ over $\unit+\unit$ there is a function
  \begin{align*}
    \ind{\unit+\unit}:P(t_0)\to \Big(P(t_1)\to \prd{t:\unit+\unit}P(t)\Big)
  \end{align*}
  satisfying
  \begin{align*}
    \ind{\unit+\unit}(p_0,p_1,t_0) & \jdeq p_0 \\
    \ind{\unit+\unit}(p_0,p_1,t_1) & \jdeq p_1.
  \end{align*}
  In other words, \emph{type theory cannot distinguish between the types $\bool$ and $\unit+\unit$.}
\item For any type $A$ we can define the type $\mathsf{list}_A$ of \define{lists} elements of $A$ as the inductive type with constructors
  \begin{align*}
    \mathsf{empty\usc{}list} & : \mathsf{list}_A \\
    \mathsf{append\usc{}list} & : A \to (\mathsf{list}_A \to \mathsf{list}_A).
  \end{align*}
  \begin{subexenum}
  \item Write down the induction principle and the computation rules for $\mathsf{list}_A$.
  \item Define a function $\mathsf{length}:\mathsf{list}_A\to\N$.
  \item Define a function $\mathsf{reverse} : \mathsf{list}_A \to \mathsf{list}_A$ that reverses the order of the elements in any list.
  \item Define a function
    \begin{equation*}
      \mathsf{concat\usc{}list} : \mathsf{list}_A \to (\mathsf{list}_A \to \mathsf{list}_A)
    \end{equation*}
    that concatenates any two lists of elements in $A$.
  \item Define a function
    \begin{equation*}
      \mathsf{sum} : \mathsf{list}_\N \to \N
    \end{equation*}
    that adds all the elements in a list of natural numbers.
  \end{subexenum}
\end{exercises}
