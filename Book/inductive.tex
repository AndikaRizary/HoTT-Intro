\section{Inductive types}

Analogous to the type of natural numbers, many types can be specified as inductive types. In this lecture we introduce some further examples of inductive types: the unit type, the empty type, the booleans, coproducts, dependent pair types, and cartesian products. We also introduce the type of integers.

\subsection{The idea of general inductive types}

Just like the type of natural numbers, other inductive types are also specified by their \emph{constructors}, an \emph{induction principle}, and their \emph{computation rules}: 
\begin{enumerate}
\item The constructors tell what structure the inductive type comes equipped with. There may any finite number of constructors, even no constructors at all, in the specification of an inductive type. 
\item The induction principle specifies the data that should be provided in order to construct a section of an arbitrary type family over the inductive type. 
\item The computation rules assert that the inductively defined section agrees on the constructors with the data that was used to define the section. Thus, there is a computation rule for every constructor.
\end{enumerate}
The induction principle and computation rules can be generated automatically once the constructors are specified, but it goes beyond the scope of our course to describe general inductive types.
%For a more general treatment of inductive types, we refer to Chapter 5 of \cite{hottbook}.


\subsection{The unit type}
A straightforward example of an inductive type is the \emph{unit type}, which has just one constructor. 
Its induction principle is analogous to just the base case of induction on the natural numbers.

\begin{defn}
We define the \define{unit type}\index{1@{$\unit$}|see {unit type}}\index{unit type|textbf} to be a closed type $\unit$ equipped with a closed term\index{unit type!star@{$\ttt$}}
\begin{equation*}
\ttt:\unit,
\end{equation*}
satisfying the induction principle\index{induction principle!of unit type} that for any type family of types $P(x)$ indexed by $x:\unit$, there is a term
\begin{equation*}
\indunit : P(\ttt)\to\prd{x:\unit}P(x)
\end{equation*}
for which the computation rule\index{computation rules!of unit type}
\begin{equation*}
\indunit(p,\ttt) \jdeq p
\end{equation*}
holds. Sometimes we write $\lam{\ttt}p$ for $\indunit(p)$.
\end{defn}

The induction principle can also be used to define ordinary functions out of the unit type. Indeed, given a type $A$ we can first weaken it to obtain the constant family over $\unit$, with value $A$. Then the induction principle of the unit type provides a function
\begin{equation*}
  \indunit : A \to (\unit\to A).
\end{equation*}
In other words, by the induction principle for the unit type we obtain for every $x:A$ a function $\mathsf{pt}_x\defeq\indunit(x):\unit\to A$.

\subsection{The empty type}
The empty type is a degenerate example of an inductive type. It does \emph{not} come equipped with any constructors, and therefore there are also no computation rules. The induction principle merely asserts that any type family has a section. In other words: if we assume the empty type has a term, then we can prove anything.

\begin{defn}
We define the \define{empty type}\index{0@{$\emptyt$}|see {empty type}}\index{empty type|textbf} to be a type $\emptyt$ satisfying the induction principle\index{induction principle!of empty type} that for any family of types $P(x)$ indexed by $x:\empty$, there is a term
\begin{equation*}
\indempty : \prd{x:\emptyt}P(x).
\end{equation*}
\end{defn}

The induction principle for the empty type can also be used to construct a function
\begin{equation*}
  \emptyt\to A
\end{equation*}
for any type $A$. Indeed, to obtain this function one first weakens $A$ to obtain the constant family over $\emptyt$ with value $A$, and then the induction principle gives the desired function.

Thus we see that from the empty type anything follows. Therefore, we we see that anything follows from $A$, if we have a function from $A$ to the empty type. This motivates the following definition.

\begin{defn}
  For any type $A$ we define \define{negation} of $A$ by
  \begin{equation*}
    \neg A\defeq A\to\emptyt.
  \end{equation*}
\end{defn}

Just as one is used to in mathematics, a proof of $\neg A$ is therefore the derivation of an absurdity from the assumption that $A$ holds, i.e., a function from $A$ to $\emptyt$.

\subsection{The booleans}
\begin{defn}
We define the \define{booleans}\index{booleans|textbf}\index{2@{$\bool$}|see {booleans}} to be a type $\bool$ that comes equipped with
\begin{align*}
\bfalse & : \bool \\
\btrue & : \bool
\end{align*}
satisfying the induction principle\index{induction principle!of booleans} that for any family of types $P(x)$ indexed by $x:\bool$, there is a term
\begin{equation*}
\indbool : P(\bfalse)\to \Big(P(\btrue)\to \prd{x:\bool}P(x)\Big)
\end{equation*}
for which the computation rules\index{computation rules!of booleans}
\begin{align*}
\indbool(p_0,p_1,\bfalse) & \jdeq p_0 \\
\indbool(p_0,p_1,\btrue) & \jdeq p_1
\end{align*}
hold.
\end{defn}

Just as in the cases for the unit type and the empty type, the induction principle for the booleans can also be used to construct an ordinary function $\bool\to A$, provided that we can construct two terms of type $A$. Indeed, by the induction principle for the booleans there is a function
\begin{equation*}
  \indbool : A \to (A\to A^\bool)
\end{equation*}
for any type $A$.

\subsection{Coproducts}
\begin{defn}
Let $A$ and $B$ be types. We define the \define{coproduct}\index{coproduct}\index{disjoint sum|see {coproduct}} $A+B$\index{plus ($+$)|see {coproduct}} to be a type that comes equipped with
\begin{align*}
\inl & : A \to A+B \\
\inr & : B \to A+B
\end{align*}
satisfying the induction principle\index{induction principle!of coproduct} that for any family of types $P(x)$ indexed by $x:A+B$, there is a term
\begin{equation*}
\ind{+} : \Big(\prd{x:A}P(\inl(x))\Big)\to\Big(\prd{y:B}P(\inr(y))\Big)\to\prd{z:A+B}P(z)
\end{equation*}
for which the computation rules\index{computation rules!of coproduct}
\begin{align*}
\ind{+}(f,g,\inl(x)) & \jdeq f(x) \\
\inr{+}(f,g,\inr(y)) & \jdeq g(y)
\end{align*}
hold. Sometimes we write $[f,g]$ for $\ind{+}(f,g)$.
\end{defn}

The coproduct of two types is sometimes also called the \define{disjoint sum}.
When one thinks of types as propositions, then the coproduct plays the role of the disjunction.\index{propositions as types!disjunction}
To construct a term of type $A+B$ you first have to decide whether it is of the form $\inl$ or $\inr$, and then you construct a term of $A$ or $B$ accordingly. Of course, this is to be contrasted with the \emph{double negation translation}\index{double negation translation!disjunction} of the disjunction, which is read as `not neither $A$ nor $B$'. 

\subsection{Dependent pair types}
The \emph{dependent pair type}\index{dependent pair type|see {$\Sigma$-type}} (or $\Sigma$-type) can be thought of as a `type indexed' disjoint sum.
However, this intuition for the dependent pair type can be counterproductive once we start to do homotopy theory in type theory.
It is better to think of the $\Sigma$-type as the total space of a family of types depending continuously on a base type, just like one can have a family of spaces depending continuously on a base space (i.e., a fibration).

\begin{defn}
Let $A$ be a type in context $\Gamma$, and let $\Gamma,x:A\vdash B(x)~\mathrm{type}$ be a type family over $A$.
The \define{dependent pair type}\index{Sigma type@{$\Sigma$-type}|textbf} is defined to be the inductive type $\sm{x:A}B(x)$ in context $\Gamma$ equipped with a \define{pairing function}\index{pairing function}
\begin{equation*}
(\blank,\blank):\prd{x:A} \Big(B(x)\to \sm{y:A}B(y)\Big).
\end{equation*}
The induction principle\index{induction principle|of Sigma types@{of $\Sigma$-types}} for $\sm{x:A}B(x)$ asserts that for any family of types $P(p)$ indexed by $p:\sm{x:A}B(x)$, there is a function
\begin{equation*}
\ind{\Sigma}:\Big(\prd{x:A}{y:B(x)}P(x,y)\Big)\to\Big(\prd{p:\sm{x:A}B(x)}P(p)\Big).
\end{equation*}
satisfying the computation rule\index{computation rules!of Sigma types@{of $\Sigma$-types}}
\begin{equation*}
\ind{\Sigma}(f,(x,y))\jdeq f(x,y).
\end{equation*}
Sometimes we write $\lam{(x,y)}f(x,y)$ for $\ind{\Sigma}(\lam{x}{y}f(x,y))$. 
\end{defn}

\begin{defn}
Given a type $A$ and a type family $B$ over $A$, the \define{first projection map}\index{first projection map|textbf}\index{projection maps!first projection|textbf}
\begin{equation*}
\proj 1:\Big(\sm{x:A}B(x)\Big)\to A
\end{equation*}
is defined by induction as
\begin{equation*}
\proj 1\defeq \lam{(x,y)}x.
\end{equation*}
The \define{second projection map}\index{second projection map|textbf}\index{projection map!second projection|textbf} is a dependent function
\begin{equation*}
\proj 2 : \prd{p:\sm{x:A}B(x)} B(\proj 1(p))
\end{equation*}
defined by induction as
\begin{equation*}
\proj 2\defeq \lam{(x,y)}y.
\end{equation*}
By the computation rule we have
\begin{align*}
\proj 1 (x,y) & \jdeq x \\
\proj 2 (x,y) & \jdeq y.
\end{align*}
\end{defn}

\subsection{Cartesian products}
A special case of the $\Sigma$-type occurs when the $B$ is a type in context $\Gamma$ weakened by $A$ (i.e., $B$ is not actually depending on $A$). In this case, a term of $\sm{x:A}B$ is given as a pair consisting of a term of $A$ and a term of $B$. Thus, $\sm{x:A}B$ is the \emph{(cartesian) product} $A\times B$. Since the cartesian product is so common (just like $A\to B$ is a common special case of the dependent product), we provide its specification along with the induction principle for cartesian products.

\begin{defn}
Let $A$ and $B$ be types in context $\Gamma$. The \define{(cartesian) product}\index{cartesian product|textbf}\index{product!of types|textbf} of $A$ and $B$ is defined as the inductive type $A\times B$\index{times ($\times$)|see {cartesian product}} with constructor
\begin{equation*}
(\blank,\blank):A\to (B\to A\times B).
\end{equation*}
The induction principle\index{induction principle!of cartesian products} for $A\times B$ asserts that for any type family $P$ over $A\times B$, one has
\begin{equation*}
\ind{\times} : \Big(\prd{x:A}{y:B}P(a,b)\Big)\to\Big(\prd{p:A\times B} P(p)\Big)
\end{equation*}
satisfying the computation rule\index{computation rules!of cartesian product} that
\begin{align*}
\ind{\times}(f,(x,y)) & \jdeq f(x,y).
\end{align*}
\end{defn}

The projection maps are defined similarly to the projection maps of $\Sigma$-types. When one thinks of types as propositions\index{propositions as types!conjunction}, then $A\times B$ is interpreted as the conjunction of $A$ and $B$.

\begin{comment}
\subsection{Overview of the inductive types}
The following table gives an overview of the 'primitive' inductive types that we have introduced so far. Many types of interest can be defined in terms of these inductive types, along with the identity type which we will introduce in \cref{chap:identity}.
\begin{center}
\begin{tabular}{llll}
\toprule
name & type & constructors \\
\midrule
\define{natural numbers} & $\N$ & $\zeroN:\N$ \\
& & $\succN:\N\to \N$ & \\
\define{empty type} & $\emptyt$ & {\color{black!20}(no constructors)}\\
\define{unit type} & $\unit$ & $\ttt:\unit$ \\
\define{booleans} & $\bool$ & $\bfalse:\bool$ \\
& & $\btrue : \bool$ \\
\define{coproduct} & $A+B$ & $\inl : A \to A+B$ \\
& & $\inr : B\to A+B$ & \\
\define{product} & $A\times B$ & $(\blank,\blank):A\to (B\to A\times B)$ \\
\define{$\Sigma$-type} & $\sm{x:A}B(x)$ & $(\blank,\blank):\prd{y:A} \big(B(y)\to \sm{x:A}B(x)\big)$ \\
\bottomrule
\end{tabular}
\end{center}
\end{comment}

\subsection{The type of integers}

\begin{defn}
  We define the \define{integers}\index{integers|see Z@{$\Z$}} to be the type $\Z\defeq\nat+(\unit+\nat)$. The type of integers comes equipped with inclusion functions of the positive and negative integers
  \begin{align*}
    \mathsf{in\usc{}pos} & \defeq \inr\circ\inr \\
    \mathsf{in\usc{}neg} & \defeq \inl,
  \end{align*}
  which are both of type $\N\to\Z$, and the constants
  \begin{align*}
    -1_\Z & \defeq \mathsf{in\usc{}neg}(0)\\
    0_\Z & \defeq \inr(\inl(\ttt))\\
    1_\Z & \defeq \mathsf{in\usc{}pos}(0).
  \end{align*}
\end{defn}

In the following lemma we derive an induction principle\index{induction principle!of Z@{of $\Z$}} for $\Z$, which can be used in many familiar constructions on $\Z$, such as in the definitions of addition and multiplication.

\begin{lem}\label{lem:Z_ind}
  Consider a type family $P$ over $\Z$. If we are given
  \begin{align*}
    p_{-1} & :P(-1_\Z) \\
    p_{-S} & : \prd{n:\N}P(\mathsf{in\usc{}neg}(n))\to P(\mathsf{in\usc{}neg}(\succN(n)))\\
    p_{0} & : P(0_\Z) \\
    P_{1} & : P(1_\Z) \\
    P_{S} & : \prd{n:\N}P(\mathsf{in\usc{}pos}(n))\to P(\mathsf{in\usc{}pos}(\succN(n))),
  \end{align*}
  then we can construct a dependent function $f:\prd{k:\Z}P(k)$ for which the following judgmental equalities hold:
  \begin{align*}
    f(-1_\Z) & \jdeq p_{-1} \\
    f(\mathsf{in\usc{}neg}(\mathsf{succ}_\N(n))) & \jdeq p_{-S}(n,f(\mathsf{in\usc{}neg}(n))) \\
    f(0_\Z) & \jdeq p_{0} \\
    f(1_\Z) & \jdeq p_{1} \\
    f(\mathsf{in\usc{}pos}(\mathsf{succ}_\N(n))) & \jdeq p_S(n,f(\mathsf{in\usc{}pos}(n))).
  \end{align*}
\end{lem}

\begin{proof}
  Since $\Z$ is the coproduct of $\N$ and $\unit+\N$, it suffices to define
  \begin{align*}
    p_{inl} & : \prd{n:\N}P(\inl(n)) \\
    p_{inr} & : \prd{t:\unit+\N}P(\inr(t)).
  \end{align*}
  Note that $\mathsf{in\usc{}neg}\jdeq\inl$ and $-1_\Z\jdeq \mathsf{in\usc{}neg}(\zeroN)$. In order to define $p_{inl}$ we use induction on the natural numbers, so it suffices to define
  \begin{align*}
    p_{-1} & : P(-1) \\
    p_{-S} & : \prd{n:\N} P(\mathsf{in\usc{}neg}(n))\to P(\mathsf{in\usc{}neg}(\succN(n))).
  \end{align*}
  Similarly, we proceed by coproduct induction, followed by induction on $\unit$ in the left case and induction on $\N$ on the right case, in order to define $p_{inr}$. 
\end{proof}

As an application we define the successor function on the integers.

\begin{defn}
We define the \define{successor function}\index{successor function!on Z@{on $\Z$}|textbf} on the integers $\mathsf{succ}_\Z:\Z\to\Z$ using the induction principle of \cref{lem:Z_ind}, taking
\begin{align*}
\mathsf{succ}_\Z(-1_\Z) & \defeq 0_\N \\
\mathsf{succ}_\Z(\mathsf{in\usc{}neg}(\mathsf{succ}_\N(n))) & \defeq \mathsf{in\usc{}neg}(n) \\
\mathsf{succ}_\Z(0_\Z) & \defeq 1_\N \\
\mathsf{succ}_\Z(1_\Z) & \defeq \mathsf{in\usc{}pos}(1_\N) \\
\mathsf{succ}_\Z(\mathsf{in\usc{}pos}(\mathsf{succ}_\N(n))) & \defeq \mathsf{in\usc{}pos}(\mathsf{succ}_\N(\mathsf{succ}_\N(n))).
\end{align*}
\end{defn}

\begin{exercises}
\item \label{ex:int_pred}\index{predecessor function|textbf}Define the predecessor function $\mathsf{pred}_\Z:\Z\to \Z$.
\item \label{ex:int_group_ops}\index{group operations!on Z@{on $\Z$}}Define group operations
  \begin{align*}
    k,l & \mapsto k+l \\
    k & \mapsto -k
  \end{align*}
  on $\Z$.
\item Define multiplication on $\Z$.
\item Construct a function $F:\Z\to\Z$ that extends the Fibonacci sequence to the left
  \begin{equation*}
    \ldots,5,-3,2,-1,1,0,1,1,2,3,5,8,13,\ldots
  \end{equation*}
  in the expected way.
\item \label{ex:one_plus_one} Show that $\unit+\unit$ satisfies the same induction principle\index{induction principle!of booleans} as $\bool$, i.e., define
  \begin{align*}
    t_0 & : \unit + \unit \\
    t_1 & : \unit + \unit,
  \end{align*}
  and show that for any type family $P$ over $\unit+\unit$ there is a function
  \begin{align*}
    \ind{\unit+\unit}:P(t_0)\to \Big(P(t_1)\to \prd{t:\unit+\unit}P(t)\Big)
  \end{align*}
  satisfying
  \begin{align*}
    \ind{\unit+\unit}(p_0,p_1,t_0) & \jdeq p_0 \\
    \ind{\unit+\unit}(p_0,p_1,t_1) & \jdeq p_1.
  \end{align*}
  In other words, \emph{type theory cannot distinguish between the types $\bool$ and $\unit+\unit$.}
\end{exercises}
